{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423bfcb8",
   "metadata": {
    "papermill": {
     "duration": 0.006713,
     "end_time": "2024-02-27T19:39:02.954282",
     "exception": false,
     "start_time": "2024-02-27T19:39:02.947569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Disaster Tweet Classification Challenge\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the realm of social media, Twitter has emerged as a critical platform for real-time news and emergency communication. However, distinguishing between tweets that report on actual disasters and those that do not can be challenging, especially during crisis situations when timely and accurate information is crucial. The Kaggle competition, \"Natural Language Processing with Disaster Tweets,\" addresses this problem by challenging participants to build machine learning models capable of classifying tweets into two categories: those that pertain to real disasters and those that do not. This classification task is not only academically interesting but also has practical applications in enhancing emergency response and disaster relief efforts.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The goal of our project is to develop a model that accurately identifies disaster-related tweets. This involves several key steps:\n",
    "\n",
    "1. **Data Preparation**: Loading and cleaning the tweet data to make it suitable for analysis.\n",
    "2. **Feature Extraction**: Transforming textual data into a format that can be used by machine learning algorithms.\n",
    "3. **Model Building and Training**: Constructing a deep learning model that can learn from the features of the tweets.\n",
    "4. **Evaluation**: Assessing the model's performance on unseen data to ensure its reliability and accuracy in real-world scenarios.\n",
    "\n",
    "To achieve these objectives, we will employ a range of tools and techniques, including data visualization for exploratory analysis, natural language processing (NLP) for text manipulation, and deep learning for model construction.\n",
    "\n",
    "Let's begin by setting up our Python environment with the necessary libraries for data manipulation, visualization, machine learning, and deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebaae7a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:02.967701Z",
     "iopub.status.busy": "2024-02-27T19:39:02.967356Z",
     "iopub.status.idle": "2024-02-27T19:39:17.004044Z",
     "shell.execute_reply": "2024-02-27T19:39:17.003330Z"
    },
    "papermill": {
     "duration": 14.046022,
     "end_time": "2024-02-27T19:39:17.006348",
     "exception": false,
     "start_time": "2024-02-27T19:39:02.960326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:39:06.753965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 19:39:06.754080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 19:39:06.886262: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3db757",
   "metadata": {
    "papermill": {
     "duration": 0.005811,
     "end_time": "2024-02-27T19:39:17.018521",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.012710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "The foundation of any machine learning project is robust and thorough data preprocessing. This stage involves loading the dataset, exploring its structure, and preparing it for the subsequent analysis and modeling. Our project utilizes a dataset provided by the Kaggle competition, which comprises a collection of tweets that have been manually labeled as being about real disasters or not. This binary classification task is central to our project's goal of accurately identifying disaster-related tweets.\n",
    "\n",
    "## Loading the Dataset\n",
    "\n",
    "We begin by loading the training and testing datasets from their respective CSV files. The training dataset (`train.csv`) includes the tweets and their labels, indicating whether each tweet is about a real disaster (`1`) or not (`0`). The testing dataset (`test.csv`), on the other hand, contains tweets for which we will predict the labels using our trained model.\n",
    "\n",
    "Let's load these datasets and take a preliminary look at the structure of the training data to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a63fe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:17.032089Z",
     "iopub.status.busy": "2024-02-27T19:39:17.031574Z",
     "iopub.status.idle": "2024-02-27T19:39:17.105913Z",
     "shell.execute_reply": "2024-02-27T19:39:17.105017Z"
    },
    "papermill": {
     "duration": 0.083633,
     "end_time": "2024-02-27T19:39:17.108108",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.024475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = '/kaggle/input/nlp-getting-started/'  # Adjust the path as necessary\n",
    "df = pd.read_csv(dataset_path + 'train.csv')\n",
    "df_test = pd.read_csv(dataset_path + 'test.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49c637",
   "metadata": {
    "papermill": {
     "duration": 0.00612,
     "end_time": "2024-02-27T19:39:17.120556",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.114436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Overview\n",
    "\n",
    "After loading the dataset, it's crucial to perform an initial exploration to understand its dimensions, identify any missing values, and examine the distribution of the target variable. This step is essential for informing the preprocessing and cleaning strategies we'll need to apply before training our models.\n",
    "\n",
    "### Understanding the Dataset's Structure\n",
    "\n",
    "We start by checking the shape of our dataset to know how many instances (tweets) and features we're dealing with. It's also important to identify any missing values within our columns, as these can significantly impact the performance of our models if not handled properly.\n",
    "\n",
    "### Analyzing the Target Variable\n",
    "\n",
    "The target variable in our dataset is binary, indicating whether a tweet is about a real disaster (`1`) or not (`0`). Understanding the distribution of these classes is vital for multiple reasons:\n",
    "\n",
    "- It helps us assess the balance between the classes, which can influence the choice of models and evaluation metrics.\n",
    "- It sets the stage for any balancing techniques we might need to employ to ensure our model performs well across both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf91b83e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:17.134459Z",
     "iopub.status.busy": "2024-02-27T19:39:17.133852Z",
     "iopub.status.idle": "2024-02-27T19:39:17.310618Z",
     "shell.execute_reply": "2024-02-27T19:39:17.309715Z"
    },
    "papermill": {
     "duration": 0.185766,
     "end_time": "2024-02-27T19:39:17.312564",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.126798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7613, 5)\n",
      "\n",
      "Missing values in each column:\n",
      " id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Distribution of classes (0 = No disaster, 1 = Disaster):\n",
      "target\n",
      "0    0.57034\n",
      "1    0.42966\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset overview\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nMissing values in each column:\\n\", df.isnull().sum())\n",
    "print(\"\\nDistribution of classes (0 = No disaster, 1 = Disaster):\")\n",
    "print(df['target'].value_counts(normalize=True))\n",
    "\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribution of Disaster Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc369e",
   "metadata": {
    "papermill": {
     "duration": 0.00651,
     "end_time": "2024-02-27T19:39:17.325781",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.319271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Text Preprocessing for Natural Language Processing\n",
    "\n",
    "In the realm of Natural Language Processing (NLP), preparing the textual data for analysis or modeling is a crucial step. This process, known as text preprocessing, involves several techniques aimed at cleaning and normalizing the text data. Our goal here is to ensure the textual data is in a more analyzable and uniform format, enhancing the performance of our NLP models.\n",
    "\n",
    "#### Overview of Text Cleaning Steps:\n",
    "\n",
    "1. **Lowercasing:** Converts all characters in the text to lowercase to ensure uniformity.\n",
    "2. **Removing URLs and Handles:** Strips out web links and Twitter handles, which are often irrelevant to the text's sentiment or classification.\n",
    "3. **Eliminating Punctuation and Numbers:** Removes special characters and digits, focusing solely on words.\n",
    "4. **Stopwords Removal:** Filters out common words (such as \"the\", \"is\", \"in\") which do not add significant meaning to the text. This step is optional and based on the specific requirements of the analysis or the model being used.\n",
    "\n",
    "#### Implementation:\n",
    "\n",
    "The `clean_text` function encapsulates these preprocessing steps, utilizing regular expressions for pattern matching and removal, and the NLTK library for stopwords removal and tokenization. This function is applied to each tweet in our dataset, producing a new column `text_clean` that contains the processed textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2fa080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:17.340039Z",
     "iopub.status.busy": "2024-02-27T19:39:17.339761Z",
     "iopub.status.idle": "2024-02-27T19:39:22.043654Z",
     "shell.execute_reply": "2024-02-27T19:39:22.042690Z"
    },
    "papermill": {
     "duration": 4.713665,
     "end_time": "2024-02-27T19:39:22.045965",
     "exception": false,
     "start_time": "2024-02-27T19:39:17.332300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                          text_clean  \n",
       "0       deeds reason earthquake may allah forgive us  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  residents asked shelter place notified officer...  \n",
       "3  people receive wildfires evacuation orders cal...  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs, handles, and the hashtag symbol\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Apply the cleaning function to the text column\n",
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "df_test['text_clean'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "df[['text', 'text_clean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac3476",
   "metadata": {
    "papermill": {
     "duration": 0.006812,
     "end_time": "2024-02-27T19:39:22.060159",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.053347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparing Text Data for Model Training\n",
    "\n",
    "After cleaning the text data, the next crucial step in our NLP pipeline is preparing the textual content for model training. This involves converting the text into a numerical format that our machine learning models can understand and process. We achieve this through tokenization and sequence padding.\n",
    "\n",
    "#### Tokenization\n",
    "\n",
    "Tokenization is the process of converting text into a sequence of tokens (words or characters). We use the `Tokenizer` class from Keras, which not only tokenizes the text but also converts it into a sequence of integers, where each integer represents a unique token in a dictionary of all tokens in the dataset.\n",
    "\n",
    "1. **Fitting the Tokenizer:** We first fit the tokenizer on our cleaned text data (`text_clean` column), which builds the dictionary of token-index mappings.\n",
    "2. **Texts to Sequences:** We then convert the text into sequences of integers using the `texts_to_sequences` method.\n",
    "\n",
    "#### Sequence Padding\n",
    "\n",
    "Since neural networks require inputs to be of the same length, we use padding to ensure all sequences in our dataset have the same length. This is done by padding shorter sequences with zeros.\n",
    "\n",
    "- **Determining the Maximum Sequence Length:** We set the maximum sequence length based on the longest sequence in our dataset to avoid losing information.\n",
    "- **Padding:** We pad the sequences using the `pad_sequences` method, ensuring that all sequences have the length equal to the maximum sequence length.\n",
    "\n",
    "#### Preparing the Labels and Splitting the Data\n",
    "\n",
    "With our features (`X` and `X_test_sub`) now in a numerical format, we prepare the target labels (`y`) from our dataset and split the data into training and testing sets. This split is crucial for training our model on one subset of the data and then evaluating its performance on a separate subset, ensuring that we assess the model's ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314e656c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:22.075963Z",
     "iopub.status.busy": "2024-02-27T19:39:22.075679Z",
     "iopub.status.idle": "2024-02-27T19:39:22.419532Z",
     "shell.execute_reply": "2024-02-27T19:39:22.418757Z"
    },
    "papermill": {
     "duration": 0.35499,
     "end_time": "2024-02-27T19:39:22.422062",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.067072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text_clean'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text_clean'])\n",
    "sequences_sub = tokenizer.texts_to_sequences(df_test['text_clean'])\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_length = max(len(x) for x in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "X_test_sub = pad_sequences(sequences_sub, maxlen=max_sequence_length)\n",
    "\n",
    "# Labels\n",
    "y = df['target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6a06e",
   "metadata": {
    "papermill": {
     "duration": 0.006815,
     "end_time": "2024-02-27T19:39:22.436183",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.429368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Development and Hyperparameter Tuning\n",
    "\n",
    "In this section, we delve into the development of our neural network model for the disaster tweet classification task. Our focus is on leveraging the power of recurrent neural networks (RNNs) and exploring different architectures, including Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Bidirectional LSTM, to find the most effective model for our task.\n",
    "\n",
    "### Defining the HyperModel Class\n",
    "\n",
    "To systematically explore various model configurations and hyperparameters, we employ the concept of hypermodeling with the help of the `keras_tuner` library. A `HyperModel` is a class that allows us to define a space of hyperparameters and model architectures for the tuner to search.\n",
    "\n",
    "#### Key Components of the HyperModel:\n",
    "\n",
    "1. **Embedding Layer:** The foundation of our model, which converts tokenized text into dense vectors of fixed size. The embedding dimension (`output_dim`) is a hyperparameter we optimize, ranging from 32 to 512.\n",
    "2. **Spatial Dropout:** This regularization technique helps prevent overfitting by dropping entire 1D feature maps in the embedding layer, with the dropout rate being another hyperparameter.\n",
    "3. **Recurrent Layers:** Depending on the model type (`LSTM`, `GRU`, or `Bidirectional LSTM`), we add a recurrent layer with tunable units (neurons) and dropout rates. These layers are crucial for capturing temporal dependencies in text data.\n",
    "   - **Units:** The number of neurons in the recurrent layer, a critical factor for the model's capacity to learn.\n",
    "   - **Dropout and Recurrent Dropout:** Regularization techniques to prevent overfitting by randomly dropping units in the layer and in the recurrent connections, respectively.\n",
    "4. **Output Layer:** A dense layer with a sigmoid activation function to classify the input text into disaster or non-disaster tweets.\n",
    "\n",
    "#### Model Compilation:\n",
    "\n",
    "The model is compiled with the Adam optimizer and binary crossentropy loss, given the binary nature of our classification task. The accuracy metric is used to evaluate model performance.\n",
    "\n",
    "### Hyperparameter Tuning with Bayesian Optimization\n",
    "\n",
    "To find the best model configuration, we employ Bayesian Optimization, a strategy that seeks to minimize the number of trials by learning from past evaluations. It intelligently selects the next set of hyperparameters to evaluate based on the previous results, balancing exploration and exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3337d99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:22.451683Z",
     "iopub.status.busy": "2024-02-27T19:39:22.451405Z",
     "iopub.status.idle": "2024-02-27T19:39:22.679416Z",
     "shell.execute_reply": "2024-02-27T19:39:22.678428Z"
    },
    "papermill": {
     "duration": 0.238609,
     "end_time": "2024-02-27T19:39:22.681750",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.443141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, GRU, Bidirectional, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "\n",
    "class TextHyperModel(HyperModel):\n",
    "    def __init__(self, input_dim, max_sequence_length, model_type):\n",
    "        self.input_dim = input_dim\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.input_dim, output_dim=hp.Int('output_dim', min_value=32, max_value=512, step=32), input_length=self.max_sequence_length))\n",
    "        model.add(SpatialDropout1D(hp.Float('spatial_dropout', 0, 0.5, step=0.1)))\n",
    "        \n",
    "        if self.model_type == 'LSTM':\n",
    "            model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                           dropout=hp.Float('dropout', 0, 0.5, step=0.1),\n",
    "                           recurrent_dropout=hp.Float('recurrent_dropout', 0, 0.5, step=0.1)))\n",
    "        elif self.model_type == 'GRU':\n",
    "            model.add(GRU(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                          dropout=hp.Float('dropout', 0, 0.5, step=0.1),\n",
    "                          recurrent_dropout=hp.Float('recurrent_dropout', 0, 0.5, step=0.1)))\n",
    "        elif self.model_type == 'Bidirectional LSTM':\n",
    "            model.add(Bidirectional(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                                         dropout=hp.Float('dropout', 0, 0.5, step=0.1),\n",
    "                                         recurrent_dropout=hp.Float('recurrent_dropout', 0, 0.5, step=0.1))))\n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a46cf",
   "metadata": {
    "papermill": {
     "duration": 0.006762,
     "end_time": "2024-02-27T19:39:22.695842",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.689080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Search Process\n",
    "\n",
    "In this phase, we embark on a comprehensive hyperparameter tuning journey for our text classification model, employing the Bayesian Optimization method. This approach aims to meticulously refine our model's architecture and parameters, ensuring optimal performance on the disaster tweet classification task.\n",
    "\n",
    "### Strategy Overview\n",
    "\n",
    "We explore three distinct recurrent neural network architectures: Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Bidirectional LSTM. Each architecture offers unique characteristics and potential benefits for our task, necessitating a thorough evaluation to identify the most effective configuration.\n",
    "\n",
    "### Hyperparameter Tuning with Bayesian Optimization\n",
    "\n",
    "Bayesian Optimization stands out for its intelligent approach to hyperparameter search, leveraging past trial results to inform future search decisions. This method balances exploration of new parameter spaces with exploitation of known good configurations, aiming to find the optimal set of hyperparameters with fewer trials compared to grid or random search strategies.\n",
    "\n",
    "#### Key Steps in the Process:\n",
    "\n",
    "1. **Model Type Iteration:** We iterate over our chosen model types (LSTM, GRU, and Bidirectional LSTM), conducting a separate hyperparameter search for each to ensure a tailored and effective exploration of the parameter space.\n",
    "\n",
    "2. **Hypermodel Preparation:** For each model type, we initialize a `TextHyperModel` instance, specifying the input dimension (based on our tokenizer's vocabulary size), maximum sequence length, and the model type. This setup allows us to dynamically adjust our model's architecture and hyperparameters based on the type being evaluated.\n",
    "\n",
    "3. **Bayesian Optimization Setup:** We configure the `BayesianOptimization` tuner with our hypermodel, setting objectives, the number of trials, executions per trial, and project-specific parameters. This tuner will guide the search process, aiming to maximize validation accuracy.\n",
    "\n",
    "4. **Early Stopping:** To prevent overfitting and reduce computational waste, we employ an EarlyStopping callback. This mechanism halts training if the validation loss does not improve for a specified number of epochs, ensuring we only proceed with promising configurations.\n",
    "\n",
    "5. **Search Execution:** The tuner executes the search process, training and evaluating models across the defined hyperparameter space. It uses the training data for fitting and a portion of it for validation, adhering to the best practices for machine learning model development.\n",
    "\n",
    "6. **Best Model Selection and Saving:** Upon completion of the search, we extract and save the best-performing model for each architecture. This model represents the optimal configuration found during the search, ready for further evaluation or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d9bfcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T19:39:22.711301Z",
     "iopub.status.busy": "2024-02-27T19:39:22.710583Z",
     "iopub.status.idle": "2024-02-27T20:30:27.593733Z",
     "shell.execute_reply": "2024-02-27T20:30:27.592706Z"
    },
    "papermill": {
     "duration": 3064.893536,
     "end_time": "2024-02-27T20:30:27.596225",
     "exception": false,
     "start_time": "2024-02-27T19:39:22.702689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 45s]\n",
      "val_accuracy: 0.7931034564971924\n",
      "\n",
      "Best val_accuracy So Far: 0.7951560020446777\n",
      "Total elapsed time: 00h 21m 12s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "\n",
    "model_types = ['LSTM', 'GRU', 'Bidirectional LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"Starting hyperparameter search for {model_type}...\")\n",
    "    hypermodel = TextHyperModel(input_dim=len(tokenizer.word_index) + 1, max_sequence_length=max_sequence_length, model_type=model_type)\n",
    "\n",
    "    tuner = BayesianOptimization(\n",
    "        hypermodel,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=2,\n",
    "        directory='my_dir',\n",
    "        project_name=f'{model_type.lower()}_tuning'\n",
    "    )\n",
    "\n",
    "    # Perform hyperparameter tuning with EarlyStopping\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    tuner.search(X_train, y_train, epochs=20, validation_split=0.2, verbose=2, callbacks=[early_stopping_callback])\n",
    "\n",
    "    # After the search, retrieve the best model\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    # Save the best model\n",
    "    best_model.save(f'my_dir/best_{model_type.lower()}_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f271b",
   "metadata": {
    "papermill": {
     "duration": 0.006837,
     "end_time": "2024-02-27T20:30:27.611384",
     "exception": false,
     "start_time": "2024-02-27T20:30:27.604547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "After conducting a thorough hyperparameter tuning process, we proceed to evaluate the performance of our optimized models on the test set. This step is crucial for understanding how our models generalize to unseen data, a vital aspect of assessing their practical utility in real-world scenarios.\n",
    "\n",
    "### Models Under Evaluation\n",
    "\n",
    "We focus on three models, each representing a different recurrent neural network architecture optimized through Bayesian Optimization:\n",
    "\n",
    "- **Long Short-Term Memory (LSTM) Model**\n",
    "- **Gated Recurrent Unit (GRU) Model**\n",
    "- **Bidirectional Long Short-Term Memory (Bidirectional LSTM) Model**\n",
    "\n",
    "These models were selected for their ability to effectively capture temporal dependencies in text data, a characteristic essential for accurately classifying disaster-related tweets.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "The primary metrics for evaluation are **loss** and **accuracy**. Loss measures how well the model fits the data, with lower values indicating better performance. Accuracy, on the other hand, quantifies the proportion of correct predictions made by the model, with higher values signifying superior performance.\n",
    "\n",
    "### Evaluation Process\n",
    "\n",
    "Each model undergoes evaluation on the same test dataset, ensuring a fair and consistent comparison. This process involves calculating the loss and accuracy for each model, providing a direct measure of their predictive capabilities.\n",
    "\n",
    "#### Results\n",
    "\n",
    "- **LSTM Model Evaluation:**\n",
    "  - Test Loss: `eval_lstm_test[0]`\n",
    "  - Test Accuracy: `eval_lstm_test[1]`\n",
    "\n",
    "- **GRU Model Evaluation:**\n",
    "  - Test Loss: `eval_gru_test[0]`\n",
    "  - Test Accuracy: `eval_gru_test[1]`\n",
    "\n",
    "- **Bidirectional LSTM Model Evaluation:**\n",
    "  - Test Loss: `eval_bidirectional_lstm_test[0]`\n",
    "  - Test Accuracy: `eval_bidirectional_lstm_test[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c42133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T20:30:27.626790Z",
     "iopub.status.busy": "2024-02-27T20:30:27.626490Z",
     "iopub.status.idle": "2024-02-27T20:30:28.716326Z",
     "shell.execute_reply": "2024-02-27T20:30:28.715133Z"
    },
    "papermill": {
     "duration": 1.100393,
     "end_time": "2024-02-27T20:30:28.718678",
     "exception": false,
     "start_time": "2024-02-27T20:30:27.618285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_lstm = load_model('/kaggle/working/my_dir/best_lstm_model.h5')\n",
    "model_gru = load_model('/kaggle/working/my_dir/best_gru_model.h5')\n",
    "model_bidirectional_lstm = load_model('/kaggle/working/my_dir/best_bidirectional lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691d5dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T20:30:28.734399Z",
     "iopub.status.busy": "2024-02-27T20:30:28.734075Z",
     "iopub.status.idle": "2024-02-27T20:30:31.165919Z",
     "shell.execute_reply": "2024-02-27T20:30:31.164738Z"
    },
    "papermill": {
     "duration": 2.442082,
     "end_time": "2024-02-27T20:30:31.168031",
     "exception": false,
     "start_time": "2024-02-27T20:30:28.725949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Loss, Accuracy: [0.4590138792991638, 0.7912015914916992]\n",
      "GRU Test Loss, Accuracy: [0.48447152972221375, 0.7826657891273499]\n",
      "Bidirectional LSTM Test Loss, Accuracy: [0.4731811583042145, 0.780039370059967]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models on the test set\n",
    "eval_lstm_test = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "eval_gru_test = model_gru.evaluate(X_test, y_test, verbose=0)\n",
    "eval_bidirectional_lstm_test = model_bidirectional_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"LSTM Test Loss, Accuracy: {eval_lstm_test}\")\n",
    "print(f\"GRU Test Loss, Accuracy: {eval_gru_test}\")\n",
    "print(f\"Bidirectional LSTM Test Loss, Accuracy: {eval_bidirectional_lstm_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fa0bf",
   "metadata": {
    "papermill": {
     "duration": 0.006965,
     "end_time": "2024-02-27T20:30:31.183005",
     "exception": false,
     "start_time": "2024-02-27T20:30:31.176040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Model Evaluation\n",
    "\n",
    "In the quest to further enhance our model's performance, we turn to ensemble techniques. By combining the predictive capabilities of our previously optimized models (LSTM, GRU, and Bidirectional LSTM), we aim to leverage the strengths of each, potentially mitigating their individual weaknesses. This approach is grounded in the hypothesis that an ensemble can achieve greater generalization and robustness compared to any single model.\n",
    "\n",
    "### Ensemble Strategy\n",
    "\n",
    "Our ensemble strategy is straightforward yet powerful. We make predictions on the test dataset using each of the three models and then average these predictions. This method assumes equal weighting for each model's output, reflecting our initial hypothesis that each model contributes valuable insights. For binary classification, we apply a threshold of 0.5 to determine the final class labels.\n",
    "\n",
    "### Evaluation Metric\n",
    "\n",
    "The metric of choice for evaluating our ensemble model is **accuracy**. It provides a clear and interpretable measure of how well the ensemble model performs in classifying tweets accurately as disaster-related or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c704e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T20:30:31.198691Z",
     "iopub.status.busy": "2024-02-27T20:30:31.198391Z",
     "iopub.status.idle": "2024-02-27T20:30:33.378552Z",
     "shell.execute_reply": "2024-02-27T20:30:33.377742Z"
    },
    "papermill": {
     "duration": 2.190507,
     "end_time": "2024-02-27T20:30:33.380464",
     "exception": false,
     "start_time": "2024-02-27T20:30:31.189957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 6ms/step\n",
      "48/48 [==============================] - 0s 2ms/step\n",
      "48/48 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with each model on the test data\n",
    "predictions_lstm_test = model_lstm.predict(X_test)\n",
    "predictions_gru_test = model_gru.predict(X_test)\n",
    "predictions_bidirectional_lstm_test = model_bidirectional_lstm.predict(X_test)\n",
    "\n",
    "# Average the predictions for ensemble\n",
    "predictions_ensemble_test = (predictions_lstm_test + predictions_gru_test + predictions_bidirectional_lstm_test) / 3\n",
    "predictions_labels_test = (predictions_ensemble_test > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df863540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T20:30:33.399687Z",
     "iopub.status.busy": "2024-02-27T20:30:33.399396Z",
     "iopub.status.idle": "2024-02-27T20:30:33.405851Z",
     "shell.execute_reply": "2024-02-27T20:30:33.405011Z"
    },
    "papermill": {
     "duration": 0.01797,
     "end_time": "2024-02-27T20:30:33.407715",
     "exception": false,
     "start_time": "2024-02-27T20:30:33.389745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Test Accuracy: 0.7905449770190414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy of ensemble predictions\n",
    "ensemble_accuracy = accuracy_score(y_test, predictions_labels_test)\n",
    "print(f\"Ensemble Model Test Accuracy: {ensemble_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440627f2",
   "metadata": {
    "papermill": {
     "duration": 0.008545,
     "end_time": "2024-02-27T20:30:33.425192",
     "exception": false,
     "start_time": "2024-02-27T20:30:33.416647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kaggle Submission Preparation\n",
    "\n",
    "After fine-tuning our models and exploring the ensemble method, the final step in our journey is to prepare our predictions for submission to Kaggle. This involves generating predictions for the competition's test set using our LSTM, GRU, Bidirectional LSTM, and ensemble models, then formatting these predictions according to Kaggle's submission requirements.\n",
    "\n",
    "### Generating Predictions\n",
    "\n",
    "1. **Individual Models**: We generate predictions for the test dataset using each of the three models (LSTM, GRU, Bidirectional LSTM) separately.\n",
    "2. **Ensemble Model**: We then create ensemble predictions by averaging the predictions from the individual models. This step is crucial as it combines the strengths of each model, potentially leading to higher accuracy.\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "Given the nature of our problem (binary classification), we apply a threshold (0.5 in our case) to convert the probabilistic predictions into binary outcomes (0 or 1), representing non-disaster and disaster tweets respectively.\n",
    "\n",
    "### Preparing Submission Files\n",
    "\n",
    "We prepare four separate submission files, one for each model (LSTM, GRU, Bidirectional LSTM) and one for the ensemble predictions. Each submission file contains two columns:\n",
    "- `id`: The unique identifier for each tweet in the test set.\n",
    "- `target`: The predicted label (0 or 1) for the tweet.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Create a DataFrame for each submission, starting with the `id` column from the test dataset.\n",
    "2. Add a `target` column with the binary predictions for each model.\n",
    "3. Save each DataFrame to a CSV file, adhering to Kaggle's submission format.\n",
    "\n",
    "### Submission Files\n",
    "\n",
    "- `submission_lstm.csv`: Contains predictions from the LSTM model.\n",
    "- `submission_gru.csv`: Contains predictions from the GRU model.\n",
    "- `submission_bidirectional_lstm.csv`: Contains predictions from the Bidirectional LSTM model.\n",
    "- `submission_ensemble.csv`: Contains predictions from the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9e5d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T20:30:33.443570Z",
     "iopub.status.busy": "2024-02-27T20:30:33.443322Z",
     "iopub.status.idle": "2024-02-27T20:30:35.902671Z",
     "shell.execute_reply": "2024-02-27T20:30:35.901789Z"
    },
    "papermill": {
     "duration": 2.471318,
     "end_time": "2024-02-27T20:30:35.905118",
     "exception": false,
     "start_time": "2024-02-27T20:30:33.433800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "102/102 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "test_ids = df_test['id']\n",
    "\n",
    "# Generate predictions\n",
    "predictions_lstm = model_lstm.predict(X_test_sub)\n",
    "predictions_gru = model_gru.predict(X_test_sub)\n",
    "predictions_bidirectional_lstm = model_bidirectional_lstm.predict(X_test_sub)\n",
    "\n",
    "# Ensemble predictions: average the predictions from the individual models\n",
    "predictions_ensemble = (predictions_lstm + predictions_gru + predictions_bidirectional_lstm) / 3\n",
    "\n",
    "# Convert predictions to binary output if necessary (for binary classification tasks)\n",
    "# This step depends on your specific problem; adjust thresholds as necessary\n",
    "threshold = 0.5\n",
    "predictions_lstm_binary = (predictions_lstm > threshold).astype(int)\n",
    "predictions_gru_binary = (predictions_gru > threshold).astype(int)\n",
    "predictions_bidirectional_lstm_binary = (predictions_bidirectional_lstm > threshold).astype(int)\n",
    "predictions_ensemble_binary = (predictions_ensemble > threshold).astype(int)\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame(df_test['id'])  # Assuming test_df contains your test dataset with an 'id' column\n",
    "\n",
    "# Add predicted targets to the DataFrame\n",
    "submission_df['target'] = predictions_lstm_binary\n",
    "submission_df.to_csv('submission_lstm.csv', index=False)\n",
    "\n",
    "submission_df['target'] = predictions_gru_binary\n",
    "submission_df.to_csv('submission_bidirectional_lstm.csv',index=False)\n",
    "\n",
    "submission_df['target'] = predictions_bidirectional_lstm_binary\n",
    "submission_df.to_csv('submission_gru.csv', index=False)\n",
    "\n",
    "submission_df['target'] = predictions_ensemble_binary\n",
    "submission_df.to_csv('submission_ensemble.csv', index=False)\n",
    "# Save the submission DataFrame to a CSV file\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3098.379642,
   "end_time": "2024-02-27T20:30:38.676426",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-27T19:39:00.296784",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
